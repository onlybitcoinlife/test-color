import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from streamlit_gsheets import GSheetsConnection
import pandas as pd
import time

# Page Config
st.set_page_config(page_title="AI Beauty Advisor", page_icon="ğŸ’„")

# --- ğŸ¨ CSS for Live Face Guide ---
st.markdown(
    """
    <style>
    /* Camera Input Container */
    div[data-testid="stCameraInput"] {
        position: relative;
    }
    
    /* Face Guide Overlay */
    div[data-testid="stCameraInput"]::after {
        content: "";
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        width: 250px; /* Adjust width for face */
        height: 330px; /* Adjust height for face */
        border: 3px dashed rgba(255, 255, 255, 0.7); /* Dotted white line */
        border-radius: 50% 50% 50% 50% / 40% 40% 60% 60%; /* Inverted Egg shape (Wider top, narrower bottom) */
        box-shadow: 0 0 0 9999px rgba(0, 0, 0, 0.5); /* Dim the outside */
        pointer-events: none; /* Allow clicking through */
        z-index: 99;
    }
    
    /* Guide Text */
    div[data-testid="stCameraInput"]::before {
        content: "ì ì„  ì•ˆì— ì–¼êµ´ì„ ë§ì¶°ì£¼ì„¸ìš”";
        position: absolute;
        top: 15%;
        left: 50%;
        transform: translateX(-50%);
        color: white;
        font-weight: bold;
        font-size: 1.2rem;
        text-shadow: 1px 1px 2px black;
        z-index: 100;
        pointer-events: none;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Title and Description
st.title("ğŸ’„ AI ë·°í‹° ì–´ë“œë°”ì´ì € (Prototype)")
st.write("ì–¼êµ´ ì‚¬ì§„ì„ ì˜¬ë¦¬ë©´ AIê°€ ì–¼êµ´í˜•ê³¼ ì´ëª©êµ¬ë¹„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

# MediaPipe Setup
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# Sidebar
st.sidebar.header("ì„¤ì •")
mode = st.sidebar.radio("ë¶„ì„ ëª¨ë“œ", ["ê¸°ë³¸ ë¶„ì„ (Face Mesh)", "í¼ìŠ¤ë„ ì»¬ëŸ¬ (ì¤€ë¹„ì¤‘)", "ì„±í˜• ê²¬ì  (ì¤€ë¹„ì¤‘)"])

from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode
import av
import threading
import time

# --- ğŸ“¹ Real-time Auto Capture Logic ---
class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.face_mesh = mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.captured_image = None
        self.capture_time = 0
        self.is_aligned = False
        self.lock = threading.Lock()

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        
        # Flip horizontally for mirror effect
        img = cv2.flip(img, 1)
        h, w, c = img.shape
        
        # Convert to RGB for MediaPipe
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(img_rgb)
        
        aligned = False
        
        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                # Draw Face Mesh on Live Feed
                mp_drawing.draw_landmarks(
                    image=img,
                    landmark_list=face_landmarks,
                    connections=mp_face_mesh.FACEMESH_TESSELATION,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())

                # 1. Pose Check (Yaw)
                nose_tip_x = face_landmarks.landmark[1].x
                left_ear_x = face_landmarks.landmark[234].x
                right_ear_x = face_landmarks.landmark[454].x
                
                ear_dist = right_ear_x - left_ear_x
                nose_pos = (nose_tip_x - left_ear_x) / ear_dist
                yaw_error = abs(nose_pos - 0.5)
                
                # 2. Center Check
                nose_y = face_landmarks.landmark[1].y
                center_x_error = abs(nose_tip_x - 0.5)
                center_y_error = abs(nose_y - 0.5)
                
                # Criteria: Looking straight (yaw < 0.2) AND Centered (error < 0.3)
                # Relaxed thresholds for better usability
                if yaw_error < 0.2 and center_x_error < 0.3 and center_y_error < 0.3:
                    aligned = True
                    
                    # Draw Green Box to indicate alignment
                    cv2.rectangle(img, (int(w*0.2), int(h*0.1)), (int(w*0.8), int(h*0.9)), (0, 255, 0), 5)
                    
                    if self.capture_time == 0:
                        self.capture_time = time.time()
                        
                    elapsed = time.time() - self.capture_time
                    if elapsed > 1.0:
                        cv2.putText(img, "CAPTURED! CLICK 'ANALYZE'", (50, int(h/2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)
                        with self.lock:
                            self.captured_image = img_rgb # Save RGB image
                    else:
                        cv2.putText(img, f"Hold still... {1.0-elapsed:.1f}s", (int(w*0.3), int(h*0.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                else:
                    self.capture_time = 0 # Reset
                    # Draw Red Box/Guide
                    color = (0, 0, 255)
                    cv2.ellipse(img, (int(w/2), int(h/2)), (int(w*0.25), int(h*0.35)), 0, 0, 360, color, 2)
                    
                    # Debug Info
                    msg = "Adjust Face"
                    if yaw_error >= 0.2: msg = "Look Straight"
                    elif center_x_error >= 0.3: msg = "Center Horizontal"
                    elif center_y_error >= 0.3: msg = "Center Vertical"
                    
                    cv2.putText(img, msg, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                    cv2.putText(img, f"Yaw: {yaw_error:.2f} (Target < 0.2)", (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        # Always update latest frame for manual capture
        with self.lock:
            self.latest_frame = img_rgb
            self.is_aligned = aligned
        
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# Input Source Selection
input_source = st.radio("ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹", ["ì‚¬ì§„ ì—…ë¡œë“œ", "ì‹¤ì‹œê°„ ìë™ ì´¬ì˜ (Beta)"])

# Initialize Session State
if "captured_image" not in st.session_state:
    st.session_state["captured_image"] = None

image = None

if input_source == "ì‚¬ì§„ ì—…ë¡œë“œ":
    st.session_state["captured_image"] = None # Reset capture if switching modes
    uploaded_file = st.file_uploader("ì–¼êµ´ ì •ë©´ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        st.image(image, caption='ì—…ë¡œë“œëœ ì‚¬ì§„', use_column_width=True)

elif input_source == "ì‹¤ì‹œê°„ ìë™ ì´¬ì˜ (Beta)":
    st.info("1. ì¹´ë©”ë¼ë¥¼ ì¼œê³  ê°€ì´ë“œì— ì–¼êµ´ì„ ë§ì¶”ì„¸ìš”.\n2. ì´ˆë¡ìƒ‰ ë°•ìŠ¤ê°€ ëœ¨ê³  'CAPTURED' ë©”ì‹œì§€ê°€ ë‚˜ì˜¤ë©´...\n3. ìë™ìœ¼ë¡œ ì‚¬ì§„ì´ ì•„ë˜ì— ëœ¹ë‹ˆë‹¤!")
    
    ctx = webrtc_streamer(
        key="example",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=VideoProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )
    
    # Check if image is captured in the processor
    if ctx.video_processor:
        # Auto Capture
        if ctx.video_processor.captured_image is not None:
            if st.session_state["captured_image"] is None:
                st.session_state["captured_image"] = ctx.video_processor.captured_image
                st.rerun()
    
    # Manual Force Capture
    if st.button("ğŸ“¸ ì§€ê¸ˆ í™”ë©´ ìº¡ì²˜í•˜ê¸° (ìˆ˜ë™)"):
        if ctx.video_processor and hasattr(ctx.video_processor, 'latest_frame'):
            st.session_state["captured_image"] = ctx.video_processor.latest_frame
            st.rerun()

    # Display Captured Image
    if st.session_state["captured_image"] is not None:
        if not st.session_state.get("is_analyzing", False):
            st.success("ğŸ“¸ ì´¬ì˜ ì„±ê³µ!")
            st.image(st.session_state["captured_image"], channels="RGB", caption="ì´¬ì˜ëœ ì´ë¯¸ì§€")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸš€ ì´ ì‚¬ì§„ìœ¼ë¡œ ë¶„ì„í•˜ê¸°"):
                    st.session_state["is_analyzing"] = True
                    st.rerun()
            with col2:
                if st.button("ğŸ”„ ë‹¤ì‹œ ì°ê¸°"):
                    st.session_state["captured_image"] = None
                    st.session_state["is_analyzing"] = False
                    if ctx.video_processor:
                        ctx.video_processor.captured_image = None
                        ctx.video_processor.capture_time = 0
                    st.rerun()
        else:
            # Persist image for analysis
            image = st.session_state["captured_image"]
            
            # Show "Retake" button even during analysis (optional, maybe in sidebar or top)
            if st.sidebar.button("ğŸ”„ ë‹¤ë¥¸ ì‚¬ì§„ ì°ê¸°"):
                st.session_state["captured_image"] = None
                st.session_state["is_analyzing"] = False
                st.rerun()

if image is not None:
    
    st.write("---")
    st.subheader("ğŸ” AI ë¶„ì„ ì¤‘...")

    # Run MediaPipe Face Mesh
    with mp_face_mesh.FaceMesh(
        static_image_mode=True,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5) as face_mesh:

        results = face_mesh.process(image)

        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                # --- ğŸ›¡ï¸ Quality Control (Pose & Lighting) ---
                h, w, c = image.shape
                
                # 1. Pose Check (Yaw - Looking Left/Right)
                nose_tip_x = face_landmarks.landmark[1].x
                left_ear_x = face_landmarks.landmark[234].x
                right_ear_x = face_landmarks.landmark[454].x
                
                # Calculate relative position of nose between ears
                ear_dist = right_ear_x - left_ear_x
                nose_pos = (nose_tip_x - left_ear_x) / ear_dist # Should be approx 0.5 for frontal
                
                yaw_error = abs(nose_pos - 0.5)
                is_frontal = yaw_error < 0.1 # Allow 10% deviation
                
                # 2. Lighting Check (Brightness)
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                brightness = np.mean(gray)
                is_bright_enough = 80 < brightness < 200 # Not too dark (80), not washed out (200)

                # Display Warnings
                if not is_frontal:
                    st.warning(f"âš ï¸ ì–¼êµ´ì´ ëŒì•„ê°€ ìˆìŠµë‹ˆë‹¤. ì •ë©´ì„ ë´ì£¼ì„¸ìš”. (ì˜¤ì°¨: {yaw_error:.2f})")
                if not is_bright_enough:
                    st.warning(f"âš ï¸ ì¡°ëª…ì´ ì ì ˆí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ë°ê¸°: {brightness:.0f}/255). ë„ˆë¬´ ì–´ë‘¡ê±°ë‚˜ ë°ìŠµë‹ˆë‹¤.")

                # Draw landmarks on the image
                annotated_image = image.copy()
                mp_drawing.draw_landmarks(
                    image=annotated_image,
                    landmark_list=face_landmarks,
                    connections=mp_face_mesh.FACEMESH_TESSELATION,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())
                
                mp_drawing.draw_landmarks(
                    image=annotated_image,
                    landmark_list=face_landmarks,
                    connections=mp_face_mesh.FACEMESH_CONTOURS,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())

                st.image(annotated_image, caption='Face Mesh ë¶„ì„ ê²°ê³¼', use_column_width=True)

                # Basic Analysis Logic (Example)
                h, w, c = image.shape
                
                # Key Landmarks Indices
                # Left Eye: 33, Right Eye: 263, Nose Tip: 1, Chin: 152
                left_eye = face_landmarks.landmark[33]
                right_eye = face_landmarks.landmark[263]
                nose_tip = face_landmarks.landmark[1]
                chin = face_landmarks.landmark[152]

                # Calculate Distances (Normalized 0-1)
                eye_dist = np.sqrt((left_eye.x - right_eye.x)**2 + (left_eye.y - right_eye.y)**2)
                face_height = np.sqrt((nose_tip.x - chin.x)**2 + (nose_tip.y - chin.y)**2) # Rough approximation

                # --- ğŸ§  Advanced Analysis Logic (v2.0) ---
                
                # --- ğŸ¨ Personal Color Analysis (Colorwise.me Style) ---
                
                # 1. ğŸ§¬ Auto-Extract Colors (Skin, Hair, Eyes)
                # Helper to get average color from a point
                def get_avg_color(img, lm, w, h, offset_y=0):
                    cx, cy = int(lm.x * w), int(lm.y * h) + offset_y
                    # Boundary check
                    cx = max(0, min(cx, w-1))
                    cy = max(0, min(cy, h-1))
                    
                    # Sample 5x5 area
                    roi = img[max(0, cy-2):min(h, cy+3), max(0, cx-2):min(w, cx+3)]
                    if roi.size > 0:
                        return np.mean(roi, axis=(0, 1)).astype(int)
                    return np.array([200, 200, 200]) # Default Grey

                # Skin: Cheek (Landmark 234 is left ear/cheek area, let's move slightly inward to 205)
                skin_color_rgb = get_avg_color(image, face_landmarks.landmark[205], w, h)
                
                # Eyes: Left Iris (Landmark 468)
                eye_color_rgb = get_avg_color(image, face_landmarks.landmark[468], w, h)
                
                # Hair: Top of Forehead (Landmark 10) + Offset Upwards
                # Estimate face height to determine offset
                face_h_est = (face_landmarks.landmark[152].y - face_landmarks.landmark[10].y) * h
                hair_offset = int(-face_h_est * 0.15) # Go up 15% of face height
                hair_color_rgb = get_avg_color(image, face_landmarks.landmark[10], w, h, offset_y=hair_offset)

                # Convert to Hex for Streamlit
                def rgb_to_hex(rgb):
                    return '#{:02x}{:02x}{:02x}'.format(rgb[0], rgb[1], rgb[2])

                skin_hex = rgb_to_hex(skin_color_rgb)
                eye_hex = rgb_to_hex(eye_color_rgb)
                hair_hex = rgb_to_hex(hair_color_rgb)

                # --- ğŸ‘¤ My Color Profile UI ---
                st.divider()
                st.subheader("ğŸ‘¤ ë‚˜ì˜ í¼ìŠ¤ë„ ì»¬ëŸ¬ í”„ë¡œí•„ (My Color Profile)")
                st.caption("AIê°€ ë¶„ì„í•œ ë‹¹ì‹ ì˜ ê³ ìœ  ìƒ‰ìƒì…ë‹ˆë‹¤. ì‹¤ì œì™€ ë‹¤ë¥´ë‹¤ë©´ ëˆŒëŸ¬ì„œ ìˆ˜ì •í•´ë³´ì„¸ìš”!")
                
                col_p1, col_p2, col_p3 = st.columns(3)
                with col_p1:
                    final_skin_hex = st.color_picker("í”¼ë¶€ìƒ‰ (Skin)", skin_hex)
                with col_p2:
                    final_eye_hex = st.color_picker("ëˆˆë™ììƒ‰ (Eyes)", eye_hex)
                with col_p3:
                    final_hair_hex = st.color_picker("ë¨¸ë¦¬ìƒ‰ (Hair)", hair_hex)

                # --- ğŸ§  Season Prediction (Based on User Profile) ---
                # Convert Final Hex back to RGB for Analysis
                def hex_to_rgb(hex_code):
                    hex_code = hex_code.lstrip('#')
                    return tuple(int(hex_code[i:i+2], 16) for i in (0, 2, 4))

                analysis_color = hex_to_rgb(final_skin_hex) # Use Skin Color for main season logic
                
                # Convert to LAB for Warm/Cool
                lab_color = cv2.cvtColor(np.uint8([[analysis_color]]), cv2.COLOR_RGB2LAB)[0][0]
                L, A, B = lab_color
                
                # Convert to HSV for Light/Dark
                hsv_color = cv2.cvtColor(np.uint8([[analysis_color]]), cv2.COLOR_RGB2HSV)[0][0]
                H, S, V = hsv_color
                
                # Logic (Simplified):
                is_warm = B > 145
                predicted_season = "ë¶„ì„ ë¶ˆê°€"
                
                if is_warm:
                    if V > 150:
                        predicted_season = "ë´„ ì›œí†¤ (Spring Warm)"
                        season_desc = "ìƒê¸° ìˆê³  ë°ì€ ì´ë¯¸ì§€ê°€ ì–´ìš¸ë¦½ë‹ˆë‹¤."
                    else:
                        predicted_season = "ê°€ì„ ì›œí†¤ (Autumn Warm)"
                        season_desc = "ì°¨ë¶„í•˜ê³  ê¹Šì´ ìˆëŠ” ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤."
                else:
                    if V > 150:
                        predicted_season = "ì—¬ë¦„ ì¿¨í†¤ (Summer Cool)"
                        season_desc = "ì²­ëŸ‰í•˜ê³  ë§‘ì€ ëŠë‚Œì´ ë² ìŠ¤íŠ¸ì…ë‹ˆë‹¤."
                    else:
                        predicted_season = "ê²¨ìš¸ ì¿¨í†¤ (Winter Cool)"
                        season_desc = "ì„ ëª…í•˜ê³  ì¹´ë¦¬ìŠ¤ë§ˆ ìˆëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤."

                # Define Palettes Globally
                SEASON_PALETTES = {
                    "ë´„ ì›œí†¤ (Spring Warm)": [
                        "#FF7F50", "#FFD700", "#98FB98", "#FFA07A", # Coral, Gold, PaleGreen, LightSalmon
                        "#FF6347", "#FFE4B5", "#40E0D0", "#F0E68C"  # Tomato, Moccasin, Turquoise, Khaki
                    ],
                    "ì—¬ë¦„ ì¿¨í†¤ (Summer Cool)": [
                        "#FFB6C1", "#E6E6FA", "#87CEFA", "#D8BFD8", # LightPink, Lavender, LightSkyBlue, Thistle
                        "#F0F8FF", "#ADD8E6", "#FFC0CB", "#B0C4DE"  # AliceBlue, LightBlue, Pink, LightSteelBlue
                    ],
                    "ê°€ì„ ì›œí†¤ (Autumn Warm)": [
                        "#8B4513", "#DAA520", "#556B2F", "#CD853F", # SaddleBrown, GoldenRod, Olive, Peru
                        "#A0522D", "#808000", "#D2691E", "#F4A460"  # Sienna, Olive, Chocolate, SandyBrown
                    ],
                    "ê²¨ìš¸ ì¿¨í†¤ (Winter Cool)": [
                        "#DC143C", "#000080", "#FF00FF", "#000000", # Crimson, Navy, Magenta, Black
                        "#FFFFFF", "#4169E1", "#800080", "#2F4F4F"  # White, RoyalBlue, Purple, DarkSlateGray
                    ]
                }

                # --- ğŸ¨ Digital Palette Strip Generation ---
                def create_palette_strip(colors, height=50):
                    num_colors = len(colors)
                    strip_w = 100 * num_colors
                    strip = np.zeros((height, strip_w, 3), dtype=np.uint8)
                    
                    for i, color_hex in enumerate(colors):
                        rgb = hex_to_rgb(color_hex)
                        # CV2 uses BGR
                        bgr = (rgb[2], rgb[1], rgb[0])
                        start_x = i * 100
                        end_x = (i + 1) * 100
                        cv2.rectangle(strip, (start_x, 0), (end_x, height), bgr, -1)
                    
                    return strip

                palette_strip = create_palette_strip(SEASON_PALETTES[predicted_season])

                # 2. ğŸ“ Neoclassical Facial Canons (Golden Ratio)
                # Landmarks
                # Forehead: 10 (Top) -> 168 (Brow)
                # Nose: 168 (Brow) -> 1 (Tip)
                # Chin: 1 (Tip) -> 152 (Bottom)
                
                top_head = face_landmarks.landmark[10]
                mid_brow = face_landmarks.landmark[168]
                nose_tip = face_landmarks.landmark[1]
                chin_bottom = face_landmarks.landmark[152]
                
                # Horizontal Thirds (Vertical Heights)
                forehead_h = np.sqrt((top_head.x - mid_brow.x)**2 + (top_head.y - mid_brow.y)**2)
                nose_h = np.sqrt((mid_brow.x - nose_tip.x)**2 + (mid_brow.y - nose_tip.y)**2)
                chin_h = np.sqrt((nose_tip.x - chin_bottom.x)**2 + (nose_tip.y - chin_bottom.y)**2)
                
                total_h = forehead_h + nose_h + chin_h
                if total_h == 0: total_h = 1
                
                r1 = forehead_h / total_h * 100
                r2 = nose_h / total_h * 100
                r3 = chin_h / total_h * 100
                
                # Vertical Fifths (Horizontal Widths)
                # Left Eye: 33(Outer) - 133(Inner)
                # Inter-Eye: 133(Inner) - 362(Inner)
                # Right Eye: 362(Inner) - 263(Outer)
                
                left_eye_w = np.sqrt((face_landmarks.landmark[33].x - face_landmarks.landmark[133].x)**2 + (face_landmarks.landmark[33].y - face_landmarks.landmark[133].y)**2)
                inter_eye_w = np.sqrt((face_landmarks.landmark[133].x - face_landmarks.landmark[362].x)**2 + (face_landmarks.landmark[133].y - face_landmarks.landmark[362].y)**2)
                right_eye_w = np.sqrt((face_landmarks.landmark[362].x - face_landmarks.landmark[263].x)**2 + (face_landmarks.landmark[362].y - face_landmarks.landmark[263].y)**2)
                
                # Golden Ratio Score (K-Beauty Standard 1:1:0.8)
                # Ideal Proportions:
                # Eyes: 1:1:1 (Inter-eye : Eye Width)
                # Vertical: 1:1:0.8 (Forehead : Nose : Chin) -> Total 2.8
                # Ideal %: Forehead 35.7%, Nose 35.7%, Chin 28.6%
                
                score = 100
                
                # 1. Eye Spacing Penalty (Ideal 1.0)
                eye_ratio = inter_eye_w / left_eye_w
                score -= abs(1.0 - eye_ratio) * 40 
                
                # 2. Vertical Ratio Penalty (Ideal 1:1:0.8)
                # We compare the lower third ratio.
                # Ideal lower third is 0.8 relative to middle third (1.0)
                lower_ratio = chin_h / nose_h if nose_h > 0 else 1.0
                score -= abs(0.8 - lower_ratio) * 50 # Higher penalty for chin ratio deviation
                
                score = max(0, min(100, int(score)))

                # --- ğŸ“Š Display Results ---
                st.divider()
                st.subheader("ğŸ“‹ AI ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸ (K-Beauty Standard)")
                
                # Summary Section (Score & Season)
                col_score, col_season = st.columns(2)
                with col_score:
                    st.markdown(f"### ğŸ‘‘ ë·°í‹° ìŠ¤ì½”ì–´: **{score}ì **")
                    st.progress(score)
                    if score >= 90:
                        st.success("ìƒìœ„ 1% í™©ê¸ˆë¹„ìœ¨ì…ë‹ˆë‹¤! ğŸ‰")
                    elif score >= 80:
                        st.success("ë§¤ìš° ì¡°í™”ë¡œìš´ ë¹„ìœ¨ì…ë‹ˆë‹¤! âœ¨")
                    else:
                        st.info("ê°œì„± ìˆê³  ë§¤ë ¥ì ì¸ ë¹„ìœ¨ì…ë‹ˆë‹¤! ğŸ’«")
                
                with col_season:
                    st.markdown(f"### ğŸ¨ í¼ìŠ¤ë„ ì»¬ëŸ¬: **{predicted_season}**")
                    st.write(season_desc)
                    # Display Palette Strip
                    st.image(palette_strip, caption="âœ¨ ë‹¹ì‹ ì˜ ë² ìŠ¤íŠ¸ ì»¬ëŸ¬ íŒ”ë ˆíŠ¸", use_column_width=True)

                    # --- Data Collection Form (Google Sheets) ---
                    st.divider()
                    st.subheader("ğŸ’Œ ê²°ê³¼ ì €ì¥ ë° ë‰´ìŠ¤ë ˆí„° êµ¬ë…")
                    st.caption("ì§„ë‹¨ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³ , ë” ë§ì€ ë·°í‹° íŒì„ ë°›ì•„ë³´ì„¸ìš”!")

                    with st.form("data_collection_form"):
                        col_form1, col_form2 = st.columns(2)
                        with col_form1:
                            user_name = st.text_input("ì´ë¦„ (Name)")
                        with col_form2:
                            user_email = st.text_input("ì´ë©”ì¼ (Email)")
                        
                        user_comment = st.text_area("ë‚¨ê¸°ê³  ì‹¶ì€ ë§ (ì„ íƒì‚¬í•­)", placeholder="ì„œë¹„ìŠ¤ ì´ìš© í›„ê¸°ë‚˜ ê¶ê¸ˆí•œ ì ì„ ì ì–´ì£¼ì„¸ìš”.")
                        
                        submit_button = st.form_submit_button("ğŸ’¾ ê²°ê³¼ ì €ì¥í•˜ê¸° (Save to Database)")

                        if submit_button:
                            if not user_name or not user_email:
                                st.warning("ì´ë¦„ê³¼ ì´ë©”ì¼ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            else:
                                try:
                                    # Connect to Google Sheets
                                    conn = st.connection("gsheets", type=GSheetsConnection)
                                    
                                    # Prepare new data
                                    new_data = pd.DataFrame([
                                        {
                                            "Timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                                            "Name": user_name,
                                            "Email": user_email,
                                            "Season": predicted_season,
                                            "Best Colors": ", ".join(recommended_colors),
                                            "Comment": user_comment
                                        }
                                    ])
                                    
                                    # Read existing data (to append)
                                    # Note: This might fail if sheet is empty or doesn't exist, handle gracefully
                                    try:
                                        existing_data = conn.read(ttl=0)
                                        updated_data = pd.concat([existing_data, new_data], ignore_index=True)
                                    except Exception:
                                        # If read fails (e.g. empty sheet), start with new data
                                        updated_data = new_data
                                    
                                    # Update Sheet
                                    conn.update(data=updated_data)
                                    
                                    st.success("âœ… ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤.")
                                    st.balloons()
                                    
                                except Exception as e:
                                    st.error(f"ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\nError: {e}")
                                    st.info("â€» ë°°í¬ í™˜ê²½ì—ì„œ Google Sheets ì—°ê²° ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

                st.divider()
                
                tab1, tab2, tab3 = st.tabs(["ğŸ¨ í¼ìŠ¤ë„ ì»¬ëŸ¬ ìƒì„¸", "ğŸ“ í™©ê¸ˆë¹„ìœ¨ ë¶„ì„ ìƒì„¸", "ğŸ’„ ê°€ìƒ ë©”ì´í¬ì—… (Beta)"])
                
                with tab1:
                    st.write("#### ğŸ¨ ì „ ê³„ì ˆ ì»¬ëŸ¬ ë¹„êµ (All Seasons)")
                    st.caption("AI ì˜ˆì¸¡ì´ í‹€ë¦´ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê³„ì ˆì˜ ìƒ‰ìƒë„ ì§ì ‘ ëŒ€ë³´ë©° ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” í†¤ì„ ì°¾ì•„ë³´ì„¸ìš”!")
                    
                    # Season Selector
                    selected_season = st.radio(
                        "í™•ì¸í•˜ê³  ì‹¶ì€ ê³„ì ˆì„ ì„ íƒí•˜ì„¸ìš”:",
                        list(SEASON_PALETTES.keys()),
                        index=list(SEASON_PALETTES.keys()).index(predicted_season) if predicted_season in SEASON_PALETTES else 0,
                        horizontal=True
                    )
                    
                    # Season Descriptions
                    SEASON_DESCRIPTIONS = {
                        "ë´„ ì›œí†¤ (Spring Warm)": "ìƒê¸° ìˆê³  ë°ì€ ì´ë¯¸ì§€ê°€ ì–´ìš¸ë¦½ë‹ˆë‹¤. (Best: ì½”ë„, í”¼ì¹˜, ì˜ë¡œìš°)",
                        "ì—¬ë¦„ ì¿¨í†¤ (Summer Cool)": "ì²­ëŸ‰í•˜ê³  ë§‘ì€ ëŠë‚Œì´ ë² ìŠ¤íŠ¸ì…ë‹ˆë‹¤. (Best: íŒŒìŠ¤í…” í•‘í¬, ìŠ¤ì¹´ì´ë¸”ë£¨)",
                        "ê°€ì„ ì›œí†¤ (Autumn Warm)": "ì°¨ë¶„í•˜ê³  ê¹Šì´ ìˆëŠ” ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤. (Best: ë¸Œë¼ìš´, ì¹´í‚¤, ë¨¸ìŠ¤íƒ€ë“œ)",
                        "ê²¨ìš¸ ì¿¨í†¤ (Winter Cool)": "ì„ ëª…í•˜ê³  ì¹´ë¦¬ìŠ¤ë§ˆ ìˆëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤. (Best: ë¸”ë™, í™”ì´íŠ¸, ë¹„ë¹„ë“œ)"
                    }
                    
                    current_palette = SEASON_PALETTES[selected_season]
                    current_desc = SEASON_DESCRIPTIONS.get(selected_season, "")
                    
                    st.write(f"#### ğŸ‘— {selected_season} ë°°ê²½ ë§¤ì¹­")
                    st.info(f"ğŸ’¡ **{selected_season} íŠ¹ì§•:** {current_desc}")
                    
                    # --- ğŸ›ï¸ Styling Guide ---
                    SEASON_TIPS = {
                        "ë´„ ì›œí†¤ (Spring Warm)": {
                            "Fashion": "ë”°ëœ»í•˜ê³  ë°ì€ íŒŒìŠ¤í…” í†¤ì´ë‚˜ ë¹„ë¹„ë“œí•œ ì»¬ëŸ¬ê°€ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. (ì½”ë„, í”¼ì¹˜, ê°œë‚˜ë¦¬ìƒ‰)",
                            "Makeup": "ë³µìˆ­ì•„ë¹› ë¸”ëŸ¬ì…”ì™€ ì½”ë„/ì˜¤ë Œì§€ ë¦½ì´ ë² ìŠ¤íŠ¸! í„ì€ ê³¨ë“œ í„ì„ ì¶”ì²œí•´ìš”.",
                            "Hair": "ë°ì€ ê°ˆìƒ‰, ì˜¤ë Œì§€ ë¸Œë¼ìš´, ê³¨ë“œ ë¸Œë¼ìš´ ë“± ë”°ëœ»í•œ ê³„ì—´ì˜ ì—¼ìƒ‰ì´ í™”ì‚¬í•´ ë³´ì…ë‹ˆë‹¤.",
                            "Jewelry": "ì‹¤ë²„ë³´ë‹¤ëŠ” **ê³¨ë“œ**ë‚˜ ë¡œì¦ˆê³¨ë“œ ì•¡ì„¸ì„œë¦¬ê°€ í”¼ë¶€ì™€ ì˜ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤."
                        },
                        "ì—¬ë¦„ ì¿¨í†¤ (Summer Cool)": {
                            "Fashion": "í°ë¼ê°€ ì„ì¸ íŒŒìŠ¤í…” í†¤ì´ë‚˜ ì°¨ë¶„í•œ ê·¸ë ˆì´ì‹œ ì»¬ëŸ¬ê°€ ìš°ì•„í•¨ì„ ë”í•´ì¤ë‹ˆë‹¤. (ë¼ë²¤ë”, ìŠ¤ì¹´ì´ë¸”ë£¨)",
                            "Makeup": "ë”¸ê¸°ìš°ìœ  í•‘í¬, ë¼ë²¤ë” ë¸”ëŸ¬ì…”ê°€ ì°°ë–¡! ë¦½ì€ í•‘í¬ë‚˜ í”ŒëŸ¼ ê³„ì—´ì„ ì¶”ì²œí•´ìš”.",
                            "Hair": "ìì—°ëª¨(í‘ë°œ)ë‚˜ ì• ì‰¬ ë¸Œë¼ìš´, ì´ˆì½” ë¸Œë¼ìš´ì²˜ëŸ¼ ë¶‰ì€ê¸°ê°€ ì—†ëŠ” ì°¨ë¶„í•œ ìƒ‰ì´ ì¢‹ìŠµë‹ˆë‹¤.",
                            "Jewelry": "ê³¨ë“œë³´ë‹¤ëŠ” **ì‹¤ë²„**ë‚˜ í™”ì´íŠ¸ê³¨ë“œ, ì§„ì£¼ ì•¡ì„¸ì„œë¦¬ê°€ ê¹¨ë—í•œ ì´ë¯¸ì§€ë¥¼ ì¤ë‹ˆë‹¤."
                        },
                        "ê°€ì„ ì›œí†¤ (Autumn Warm)": {
                            "Fashion": "ê¹Šì´ ìˆê³  ì°¨ë¶„í•œ ì–´ìŠ¤(Earth) ì»¬ëŸ¬ê°€ ë¶„ìœ„ê¸° ì—¬ì‹ ìœ¼ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. (ì¹´í‚¤, ë¨¸ìŠ¤íƒ€ë“œ, ë²½ëŒìƒ‰)",
                            "Makeup": "ìŒì˜ ë©”ì´í¬ì—…ì´ ê°€ì¥ ì˜ ì–´ìš¸ë ¤ìš”. ë§ë¦° ì¥ë¯¸(MLBB), ë¸Œë¦­ ë ˆë“œ ë¦½ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                            "Hair": "ë‹¤í¬ ë¸Œë¼ìš´, ì¹´í‘¸ì¹˜ë…¸ ë¸Œë¼ìš´ ë“± ê¹Šê³  í’ì„±í•œ ì»¬ëŸ¬ê°€ ê³ ê¸‰ìŠ¤ëŸ¬ì›Œ ë³´ì…ë‹ˆë‹¤.",
                            "Jewelry": "ê´‘íƒì´ ì ì€ **ì•¤í‹± ê³¨ë“œ**ë‚˜ ë¸Œë¡ ì¦ˆ, ìš°ë“œ ì†Œì¬ì˜ ì•¡ì„¸ì„œë¦¬ê°€ ë©‹ìŠ¤ëŸ½ìŠµë‹ˆë‹¤."
                        },
                        "ê²¨ìš¸ ì¿¨í†¤ (Winter Cool)": {
                            "Fashion": "ì„ ëª…í•˜ê³  ëŒ€ë¹„ê°€ í™•ì‹¤í•œ ì»¬ëŸ¬ê°€ ì¹´ë¦¬ìŠ¤ë§ˆë¥¼ ì‚´ë ¤ì¤ë‹ˆë‹¤. (ë¸”ë™&í™”ì´íŠ¸, ë¡œì–„ ë¸”ë£¨, í•«í•‘í¬)",
                            "Makeup": "ì•„ì´ë¼ì´ë„ˆë¥¼ ê¹”ë”í•˜ê²Œ ê·¸ë¦¬ê³ , ë ˆë“œë‚˜ í‘¸ì‹œì•„ í•‘í¬ ë¦½ìœ¼ë¡œ í¬ì¸íŠ¸ë¥¼ ì£¼ì„¸ìš”.",
                            "Hair": "ìœ¤ê¸° ë‚˜ëŠ” í‘ë°œ(ë¸”ë£¨ ë¸”ë™)ì´ ê°€ì¥ ë² ìŠ¤íŠ¸! ì• ë§¤í•œ ê°ˆìƒ‰ë³´ë‹¤ëŠ” í™•ì‹¤í•œ ë¸”ë™ì´ ë‚«ìŠµë‹ˆë‹¤.",
                            "Jewelry": "ë°˜ì§ì´ëŠ” **ì‹¤ë²„**, í™”ì´íŠ¸ê³¨ë“œ, ë‹¤ì´ì•„ëª¬ë“œì²˜ëŸ¼ í™”ë ¤í•˜ê³  ì°¨ê°€ìš´ ëŠë‚Œì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤."
                        }
                    }
                    
                    tips = SEASON_TIPS.get(selected_season, {})
                    
                    with st.expander(f"ğŸ›ï¸ {selected_season} ìŠ¤íƒ€ì¼ë§ ê°€ì´ë“œ (í´ë¦­)", expanded=True):
                        c1, c2 = st.columns(2)
                        with c1:
                            st.markdown(f"**ğŸ‘š íŒ¨ì…˜ (Fashion)**\n- {tips['Fashion']}")
                            st.markdown(f"**ğŸ’ ì£¼ì–¼ë¦¬ (Jewelry)**\n- {tips['Jewelry']}")
                        with c2:
                            st.markdown(f"**ğŸ’„ ë©”ì´í¬ì—… (Makeup)**\n- {tips['Makeup']}")
                            st.markdown(f"**ğŸ’‡â€â™€ï¸ í—¤ì–´ (Hair)**\n- {tips['Hair']}")
                    
                    # Single Color Selection for Detail View
                    st.write("ğŸ‘‡ **ìƒì„¸ ì»¬ëŸ¬ ì„ íƒ (í´ë¦­í•˜ì—¬ ë³€ê²½)**")
                    selected_color = st.radio(
                        "í…ŒìŠ¤íŠ¸í•  ìƒ‰ìƒì„ ì„ íƒí•˜ì„¸ìš”:",
                        current_palette,
                        horizontal=True,
                        label_visibility="collapsed"
                    )
                    
                    def apply_background(img, landmarks, hex_color):
                        # Hex to BGR
                        hex_color = hex_color.lstrip('#')
                        r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
                        color_bgr = (b, g, r)
                        
                        h, w, c = img.shape
                        
                        # Jawline Indices (Left Ear -> Chin -> Right Ear)
                        jawline_indices = [
                            234, 93, 132, 58, 172, 136, 150, 149, 176, 148, 152, 
                            377, 400, 378, 379, 365, 397, 288, 361, 323, 454
                        ]
                        
                        points = []
                        for idx in jawline_indices:
                            pt = landmarks.landmark[idx]
                            points.append((int(pt.x * w), int(pt.y * h)))
                        
                        # Add bottom corners to create a "bib" or "clothing" shape
                        points.append((w, h)) # Bottom Right
                        points.append((0, h)) # Bottom Left
                        
                        points = np.array(points, np.int32)
                        
                        # Create Mask
                        mask = np.zeros((h, w), dtype=np.uint8)
                        cv2.fillPoly(mask, [points], 255)
                        
                        # Soften edges
                        mask = cv2.GaussianBlur(mask, (15, 15), 0)
                        
                        # Create Color Layer
                        color_layer = np.full((h, w, 3), color_bgr, dtype=np.uint8)
                        
                        # Combine: Original Image + Color Layer (masked)
                        # We want the color to be ON the mask (Neck/Chest), and original image elsewhere.
                        mask_norm = mask.astype(float) / 255.0
                        mask_norm = np.repeat(mask_norm[:, :, np.newaxis], 3, axis=2)
                        
                        # Output = Color * Mask + Original * (1 - Mask)
                        out = (color_layer.astype(float) * mask_norm + img.astype(float) * (1.0 - mask_norm)).astype(np.uint8)
                        
                        return out

                    # Display Large Preview
                    if selected_color:
                        large_bg_img = apply_background(image, face_landmarks, selected_color)
                        st.image(large_bg_img, caption=f"ì„ íƒëœ ì»¬ëŸ¬: {selected_color}", use_column_width=True)
                    
                    # Display Palette Grid (Small)
                    with st.expander("ğŸ¨ ì „ì²´ íŒ”ë ˆíŠ¸ ëª¨ì•„ë³´ê¸° (í´ë¦­í•´ì„œ í¼ì¹˜ê¸°)"):
                        cols1 = st.columns(4)
                        for i in range(4):
                            with cols1[i]:
                                bg_img = apply_background(image, face_landmarks, current_palette[i])
                                st.image(bg_img, caption=current_palette[i], use_column_width=True)
                        
                        cols2 = st.columns(4)
                        for i in range(4):
                            with cols2[i]:
                                bg_img = apply_background(image, face_landmarks, current_palette[i+4])
                                st.image(bg_img, caption=current_palette[i+4], use_column_width=True)
                
                with tab2:
                    st.write("#### 1. ì–¼êµ´ ì„¸ë¡œ ë¹„ìœ¨ (íŠ¸ë Œë“œ 1:1:0.8)")
                    st.caption("ìµœì‹  í•œêµ­ ë¯¸ì¸ìƒì€ í•˜ì•ˆë¶€(í„±)ê°€ ì§§ì€ 'ë™ì•ˆ ë¹„ìœ¨'ì„ ì„ í˜¸í•©ë‹ˆë‹¤.")
                    
                    # Normalize to Middle Third = 1.0
                    if nose_h > 0:
                        r_top = forehead_h / nose_h
                        r_mid = 1.0
                        r_bot = chin_h / nose_h
                    else:
                        r_top, r_mid, r_bot = 1.0, 1.0, 1.0
                        
                    st.write(f"- ìƒì•ˆë¶€(ì´ë§ˆ): **{r_top:.2f}**")
                    st.write(f"- ì¤‘ì•ˆë¶€(ì½”): **{r_mid:.2f}**")
                    st.write(f"- í•˜ì•ˆë¶€(í„±): **{r_bot:.2f}** (ì´ìƒì  0.8)")
                    
                    if 0.75 <= r_bot <= 0.85:
                        st.success("âœ¨ ì™„ë²½í•œ 'ë™ì•ˆ(Baby Face)' ë¹„ìœ¨ì…ë‹ˆë‹¤! (1:1:0.8)")
                    elif r_bot < 0.75:
                        st.info("ğŸ’¡ í•˜ì•ˆë¶€ê°€ ë§¤ìš° ì§§ì•„ ê·€ì—¬ìš´ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")
                    else:
                        st.info("ğŸ’¡ í•˜ì•ˆë¶€ê°€ ê¸´ í¸ìœ¼ë¡œ, ì„±ìˆ™í•˜ê³  ìš°ì•„í•œ 'ë°°ìš°ìƒ' ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")

                    st.markdown("---")
                    st.write("#### 2. ëˆˆ ë¹„ìœ¨ (ì´ìƒì  1:1:1)")
                    st.caption(f"ëˆˆ ë„ˆë¹„ : ë¯¸ê°„ ë„ˆë¹„ = 1 : {eye_ratio:.2f}")
                    
                    if 0.9 <= eye_ratio <= 1.1:
                        st.success("ëˆˆê³¼ ë¯¸ê°„ì˜ ë¹„ìœ¨ì´ í™©ê¸ˆë¹„ìœ¨(1:1)ì— ì™„ë²½í•˜ê²Œ ë¶€í•©í•©ë‹ˆë‹¤!")
                    elif eye_ratio > 1.1:
                        st.warning("ë¯¸ê°„ì´ ëˆˆë³´ë‹¤ ë„“ìŠµë‹ˆë‹¤. (ì•íŠ¸ì„ ë©”ì´í¬ì—… ì¶”ì²œ)")
                    else:
                        st.warning("ë¯¸ê°„ì´ ëˆˆë³´ë‹¤ ì¢ìŠµë‹ˆë‹¤. (ë’¤íŠ¸ì„/ë°‘íŠ¸ì„ ë©”ì´í¬ì—… ì¶”ì²œ)")
                
                with tab3:
                    st.write("#### ğŸ’„ ê°€ìƒ ë©”ì´í¬ì—… (Virtual Makeover)")
                    st.info("ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì—¬ ë‚´ ì–¼êµ´ì— ì§ì ‘ ì ìš©í•´ë³´ì„¸ìš”!")
                    
                    makeover_img = image.copy()
                    
                    # 1. Virtual Lipstick
                    st.markdown("##### ğŸ’‹ ë¦½ìŠ¤í‹± (Lipstick)")
                    lip_color = st.color_picker("ë¦½ìŠ¤í‹± ìƒ‰ìƒ ì„ íƒ", "#FF0055")
                    lip_opacity = st.slider("ì§„í•˜ê¸° (Opacity)", 0.0, 1.0, 0.4)
                    
                    def apply_lipstick(img, landmarks, hex_color, opacity):
                        # Hex to RGB
                        hex_color = hex_color.lstrip('#')
                        r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
                        color_rgb = (r, g, b)
                        
                        h, w, c = img.shape
                        
                        # Lip Indices (Outer)
                        lip_indices = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146]
                        
                        points = []
                        for idx in lip_indices:
                            pt = landmarks.landmark[idx]
                            points.append((int(pt.x * w), int(pt.y * h)))
                        points = np.array(points, np.int32)
                        
                        # Create Mask
                        mask = np.zeros((h, w), dtype=np.uint8)
                        cv2.fillPoly(mask, [points], 255)
                        mask = cv2.GaussianBlur(mask, (7, 7), 0) # Soft edges
                        
                        # Create Color Layer
                        color_layer = np.full((h, w, 3), color_rgb, dtype=np.uint8)
                        
                        # Blend
                        mask_norm = (mask.astype(float) / 255.0) * opacity
                        mask_norm = np.repeat(mask_norm[:, :, np.newaxis], 3, axis=2)
                        
                        out = (color_layer.astype(float) * mask_norm + img.astype(float) * (1.0 - mask_norm)).astype(np.uint8)
                        return out

                    makeover_img = apply_lipstick(makeover_img, face_landmarks, lip_color, lip_opacity)
                    
                    # 2. Virtual Hair Dye (Beta) - Improved
                    st.markdown("##### ğŸ’‡â€â™€ï¸ í—¤ì–´ ì—¼ìƒ‰ (Hair Dye) - Beta")
                    
                    dye_mode = st.radio("ì—¼ìƒ‰ ì˜ì—­ ì„ íƒ ë°©ì‹", ["ìë™ (Auto)", "ìˆ˜ë™ ê·¸ë¦¬ê¸° (Manual Draw)"], horizontal=True)
                    
                    dye_color = st.color_picker("ì—¼ìƒ‰í•  ìƒ‰ìƒ ì„ íƒ", "#8B4513")
                    dye_intensity = st.slider("ì—¼ìƒ‰ ê°•ë„", 0.0, 1.0, 0.5)

                    def apply_hair_dye(img, seed_hex, target_hex, intensity, tolerance, landmarks, skin_rgb=None, correction_mask=None, return_mask=False):
                        h, w, c = img.shape
                        
                        # 1. Color Threshold Mask (HSV)
                        hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
                        
                        # Seed Color (Source)
                        seed_hex = seed_hex.lstrip('#')
                        sr, sg, sb = tuple(int(seed_hex[i:i+2], 16) for i in (0, 2, 4))
                        seed_bgr = np.uint8([[[sb, sg, sr]]])
                        seed_hsv = cv2.cvtColor(seed_bgr, cv2.COLOR_BGR2HSV)[0][0]
                        
                        lower_bound = np.array([max(0, seed_hsv[0] - tolerance), 20, 20]) 
                        upper_bound = np.array([min(179, seed_hsv[0] + tolerance), 255, 255])
                        
                        color_mask = cv2.inRange(hsv_img, lower_bound, upper_bound)
                        
                        # 2. Selfie Segmentation (Exclude Background)
                        mp_selfie_segmentation = mp.solutions.selfie_segmentation
                        with mp_selfie_segmentation.SelfieSegmentation(model_selection=1) as selfie_seg:
                            res = selfie_seg.process(img)
                            # condition: > 0.5 is person
                            person_mask = (res.segmentation_mask > 0.5).astype(np.uint8) * 255
                        
                        # 3. Face Exclusion Mask (Protect Face Skin)
                        face_mask = np.zeros((h, w), dtype=np.uint8)
                        face_oval_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]
                        
                        face_points = []
                        for idx in face_oval_indices:
                            pt = landmarks.landmark[idx]
                            face_points.append((int(pt.x * w), int(pt.y * h)))
                        
                        if face_points:
                            cv2.fillPoly(face_mask, [np.array(face_points)], 255)
                            face_mask = cv2.dilate(face_mask, np.ones((15,15), np.uint8), iterations=1)

                        # 4. Skin Color Exclusion (Protect Neck/Body Skin)
                        skin_exclusion_mask = np.zeros((h, w), dtype=np.uint8)
                        if skin_rgb is not None:
                            skin_bgr = np.uint8([[[skin_rgb[2], skin_rgb[1], skin_rgb[0]]]])
                            skin_hsv = cv2.cvtColor(skin_bgr, cv2.COLOR_BGR2HSV)[0][0]
                            
                            # Wide range for skin to catch shadows on neck
                            s_lower = np.array([max(0, skin_hsv[0] - 20), 30, 30])
                            s_upper = np.array([min(179, skin_hsv[0] + 20), 255, 255])
                            
                            skin_exclusion_mask = cv2.inRange(hsv_img, s_lower, s_upper)
                            skin_exclusion_mask = cv2.dilate(skin_exclusion_mask, np.ones((5,5), np.uint8), iterations=2)

                        # 5. Combine Masks
                        # Hair = (Color Match) AND (Person) AND (NOT Face) AND (NOT Skin)
                        final_mask = cv2.bitwise_and(color_mask, person_mask)
                        final_mask = cv2.bitwise_and(final_mask, cv2.bitwise_not(face_mask))
                        final_mask = cv2.bitwise_and(final_mask, cv2.bitwise_not(skin_exclusion_mask))
                        
                        # 6. Apply Correction Mask (User Add/Remove)
                        if correction_mask is not None:
                            # Green (Channel 1) = ADD
                            mask_add = correction_mask[:, :, 1]
                            # Red (Channel 0) = REMOVE
                            mask_remove = correction_mask[:, :, 0]
                            
                            # Add first
                            final_mask = cv2.bitwise_or(final_mask, mask_add)
                            # Then Remove
                            final_mask = cv2.bitwise_and(final_mask, cv2.bitwise_not(mask_remove))

                        final_mask = cv2.GaussianBlur(final_mask, (5, 5), 0)

                        if return_mask:
                            # Return mask as RGB image for visualization
                            return cv2.cvtColor(final_mask, cv2.COLOR_GRAY2RGB)

                        # Apply Color (LAB Blending for Natural Look)
                        target_hex = target_hex.lstrip('#')
                        tr, tg, tb = tuple(int(target_hex[i:i+2], 16) for i in (0, 2, 4))
                        target_rgb = np.uint8([[[tr, tg, tb]]])
                        target_lab = cv2.cvtColor(target_rgb, cv2.COLOR_RGB2LAB)[0][0]
                        t_l, t_a, t_b = int(target_lab[0]), int(target_lab[1]), int(target_lab[2])

                        # Convert Image to LAB
                        img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
                        l, a, b = cv2.split(img_lab)

                        # Prepare Mask
                        mask_f = final_mask.astype(float) / 255.0 * intensity
                        
                        # Blend A and B channels (Color)
                        a_new = (a.astype(float) * (1.0 - mask_f) + t_a * mask_f).astype(np.uint8)
                        b_new = (b.astype(float) * (1.0 - mask_f) + t_b * mask_f).astype(np.uint8)
                        
                        # Blend L channel slightly (Optional: 20% influence) to allow some lightness change but keep texture
                        # Too much L blending kills texture. 0.2 is safe.
                        l_new = (l.astype(float) * (1.0 - mask_f * 0.3) + t_l * (mask_f * 0.3)).astype(np.uint8)

                        # Merge and Convert back
                        out_lab = cv2.merge([l_new, a_new, b_new])
                        out = cv2.cvtColor(out_lab, cv2.COLOR_LAB2RGB)
                        
                        return out

                    if dye_mode == "ìë™ (Auto)":
                        st.caption("â€» 'ë‚´ ë¨¸ë¦¬ìƒ‰ ì§€ì •'ì„ ì¡°ì ˆí•˜ì—¬ ì—¼ìƒ‰ë  ì˜ì—­ì„ ì„ íƒí•˜ì„¸ìš”.")
                        c_h1, c_h2 = st.columns(2)
                        with c_h1:
                            # Default to the auto-detected hair color
                            def rgb_to_hex(rgb): return '#{:02x}{:02x}{:02x}'.format(rgb[0], rgb[1], rgb[2])
                            default_hair_hex = rgb_to_hex(hair_color_rgb)
                            ref_hair_color = st.color_picker("ë‚´ ë¨¸ë¦¬ìƒ‰ ì§€ì • (Source)", default_hair_hex, help="ì´ ìƒ‰ìƒê³¼ ë¹„ìŠ·í•œ ì˜ì—­ì´ ì—¼ìƒ‰ë©ë‹ˆë‹¤.")
                        with c_h2:
                            color_tolerance = st.slider("ìƒ‰ìƒ ì¸ì‹ ë²”ìœ„ (Tolerance)", 10, 150, 50)
                        
                        show_mask = st.checkbox("ğŸ§ ì—¼ìƒ‰ ì˜ì—­(ë§ˆìŠ¤í¬) ë¯¸ë¦¬ë³´ê¸°")
                        
                        # Correction Tool
                        use_correction = st.checkbox("ğŸ› ï¸ ì˜ì—­ ìˆ˜ì • (ì¶”ê°€/ì œê±°)")
                        correction_mask_full = None
                        
                        if use_correction:
                            st.caption("ğŸ‘‡ 'ì¶”ê°€'ëŠ” ì´ˆë¡ìƒ‰, 'ì œê±°'ëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ì¹ í•´ì§‘ë‹ˆë‹¤.")
                            
                            # Resize for Canvas
                            canvas_width = 600
                            aspect_ratio = image.shape[0] / image.shape[1]
                            canvas_height = int(canvas_width * aspect_ratio)
                            
                            # Ensure image is uint8 and RGB for PIL
                            if image.dtype != np.uint8:
                                image_u8 = (image * 255).astype(np.uint8) if image.max() <= 1.0 else image.astype(np.uint8)
                            else:
                                image_u8 = image
                                
                            img_pil = Image.fromarray(image_u8).convert("RGB")
                            img_resized = img_pil.resize((canvas_width, canvas_height))
                            
                            col_tool1, col_tool2 = st.columns([1, 2])
                            with col_tool1:
                                brush_mode = st.radio("ë¸ŒëŸ¬ì‰¬ ëª¨ë“œ", ["ì¶”ê°€ (Add)", "ì œê±° (Remove)"])
                            with col_tool2:
                                stroke_width = st.slider("ë¸ŒëŸ¬ì‰¬ í¬ê¸°", 1, 50, 20)
                                
                            if brush_mode == "ì¶”ê°€ (Add)":
                                stroke_color = "#00FF00" # Green
                                fill_color = "rgba(0, 255, 0, 0.3)"
                            else:
                                stroke_color = "#FF0000" # Red
                                fill_color = "rgba(255, 0, 0, 0.3)"
                            
                            canvas_result = st_canvas(
                                fill_color=fill_color,
                                stroke_width=stroke_width,
                                stroke_color=stroke_color,
                                background_image=img_resized,
                                update_streamlit=True,
                                height=canvas_height,
                                width=canvas_width,
                                drawing_mode="freedraw",
                                key="correction_canvas_v2",
                            )
                            
                            if canvas_result.image_data is not None:
                                mask_resized = canvas_result.image_data # RGBA
                                if np.sum(mask_resized) > 0:
                                    correction_mask_full = cv2.resize(mask_resized, (image.shape[1], image.shape[0]))
                        
                        # Apply Auto Dye (Existing Function)
                        makeover_img = apply_hair_dye(makeover_img, ref_hair_color, dye_color, dye_intensity, color_tolerance, face_landmarks, skin_rgb=skin_color_rgb, correction_mask=correction_mask_full, return_mask=show_mask)
                        st.image(makeover_img, caption="âœ¨ ë©”ì´í¬ì—… & ì—¼ìƒ‰ ì ìš© ê²°ê³¼" if not show_mask else "ğŸ§ ì—¼ìƒ‰ ì˜ì—­ ë§ˆìŠ¤í¬ (í°ìƒ‰ ë¶€ë¶„ì´ ì—¼ìƒ‰ë¨)", use_column_width=True)

                    else: # Manual Draw Mode
                        st.caption("ğŸ‘‡ ì‚¬ì§„ ìœ„ì— ì—¼ìƒ‰í•˜ê³  ì‹¶ì€ ë¶€ìœ„ë¥¼ ì§ì ‘ ì¹ í•´ì£¼ì„¸ìš”!")
                        
                        # 1. Resize for Canvas (to fit screen)
                        canvas_width = 600
                        aspect_ratio = image.shape[0] / image.shape[1]
                        canvas_height = int(canvas_width * aspect_ratio)
                        
                        img_pil = Image.fromarray(image)
                        img_resized = img_pil.resize((canvas_width, canvas_height))
                        
                        # Stroke width
                        stroke_width = st.slider("ë¸ŒëŸ¬ì‰¬ í¬ê¸°", 1, 50, 20)
                        
                        canvas_result = st_canvas(
                            fill_color="rgba(255, 165, 0, 0.3)",
                            stroke_width=stroke_width,
                            stroke_color="#ffffff",
                            background_image=img_resized,
                            update_streamlit=True,
                            height=canvas_height,
                            width=canvas_width,
                            drawing_mode="freedraw",
                            key="canvas",
                        )
                        
                        if canvas_result.image_data is not None:
                            # Get the drawn mask (Alpha channel) from the resized canvas
                            mask_resized = canvas_result.image_data[:, :, 3]
                            
                            if np.sum(mask_resized) > 0:
                                # 2. Scale Mask back to Original Size
                                mask = cv2.resize(mask_resized, (image.shape[1], image.shape[0]))
                                
                                # Apply Dye using Manual Mask (LAB Blending)
                                h, w, c = image.shape
                                
                                # Target Color LAB
                                target_hex = dye_color.lstrip('#')
                                tr, tg, tb = tuple(int(target_hex[i:i+2], 16) for i in (0, 2, 4))
                                target_rgb = np.uint8([[[tr, tg, tb]]])
                                target_lab = cv2.cvtColor(target_rgb, cv2.COLOR_RGB2LAB)[0][0]
                                t_l, t_a, t_b = int(target_lab[0]), int(target_lab[1]), int(target_lab[2])
                                
                                # Image LAB
                                img_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                                l, a, b = cv2.split(img_lab)
                                
                                # Mask
                                mask_f = (mask.astype(float) / 255.0) * dye_intensity
                                
                                # Blend
                                a_new = (a.astype(float) * (1.0 - mask_f) + t_a * mask_f).astype(np.uint8)
                                b_new = (b.astype(float) * (1.0 - mask_f) + t_b * mask_f).astype(np.uint8)
                                l_new = (l.astype(float) * (1.0 - mask_f * 0.3) + t_l * (mask_f * 0.3)).astype(np.uint8)
                                
                                out_lab = cv2.merge([l_new, a_new, b_new])
                                out = cv2.cvtColor(out_lab, cv2.COLOR_LAB2RGB)
                                
                                # Apply previous makeover effects (Lipstick) if any? 
                                # Note: 'makeover_img' has lipstick. 'image' is original.
                                # If we want to stack, we should use 'makeover_img' as base.
                                # Let's use makeover_img as base to keep lipstick.
                                
                                img_lab_base = cv2.cvtColor(makeover_img, cv2.COLOR_RGB2LAB)
                                l_base, a_base, b_base = cv2.split(img_lab_base)
                                
                                a_final = (a_base.astype(float) * (1.0 - mask_f) + t_a * mask_f).astype(np.uint8)
                                b_final = (b_base.astype(float) * (1.0 - mask_f) + t_b * mask_f).astype(np.uint8)
                                l_final = (l_base.astype(float) * (1.0 - mask_f * 0.3) + t_l * (mask_f * 0.3)).astype(np.uint8)
                                
                                out_lab_final = cv2.merge([l_final, a_final, b_final])
                                out = cv2.cvtColor(out_lab_final, cv2.COLOR_LAB2RGB)
                                
                                st.image(out, caption="âœ¨ ìˆ˜ë™ ì—¼ìƒ‰ ì ìš© ê²°ê³¼", use_column_width=True)
                            else:
                                st.info("ğŸ‘† ìœ„ ì‚¬ì§„ì— ì—¼ìƒ‰í•  ë¶€ìœ„ë¥¼ ì¹ í•´ë³´ì„¸ìš”.")

                st.warning("âš ï¸ ì´ ê²°ê³¼ëŠ” AIì˜ ì¶”ì •ì¹˜ì´ë©°, ì¡°ëª…ê³¼ ê°ë„ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
else:
    st.info("ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
